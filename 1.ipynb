{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures,OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error, confusion_matrix, classification_report\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import uniform, randint\n",
    "import base64   \n",
    "from io import BytesIO          \n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import f_oneway\n",
    "from collections import defaultdict\n",
    "from scipy.stats import chi2_contingency, f_oneway\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtraML:\n",
    "    def __init__(self, problem_type='regression', target_column=None):\n",
    "        self.problem_type = problem_type.lower()\n",
    "        if self.problem_type != 'regression':\n",
    "            raise ValueError(\"This implementation only supports regression problems.\")\n",
    "        \n",
    "        self.models = {\n",
    "            'LinearRegression': LinearRegression(),\n",
    "            'DecisionTree': DecisionTreeRegressor(random_state=42),\n",
    "            'KNN': KNeighborsRegressor(),\n",
    "            'MeanBaseline': DummyRegressor(strategy='mean'),\n",
    "            'MedianBaseline': DummyRegressor(strategy='median')\n",
    "        }\n",
    "        \n",
    "        self.best_model = None\n",
    "        self.best_score = float('inf')\n",
    "        self.best_params = None\n",
    "        self.report = []\n",
    "        self.target_column = target_column\n",
    "\n",
    "    def add_to_report(self, title, content):\n",
    "        self.report.append({'title': title, 'content': content})\n",
    "\n",
    "    def capture_dataframe_head(self, df, title):\n",
    "        head_html = df.head().to_html(classes='dataframe')\n",
    "        self.add_to_report(title, f\"<div style='overflow-x: auto;'>{head_html}</div>\")\n",
    "\n",
    "    def compute_correlation_ratio(self, categories, measurements):\n",
    "        categories = pd.Categorical(categories)\n",
    "        categories_unique = categories.categories\n",
    "        measurements_grouped = [measurements[categories == cat] for cat in categories_unique]\n",
    "        measurements_grouped = [group for group in measurements_grouped if len(group) > 0]\n",
    "        \n",
    "        ssb = sum(len(group) * (np.mean(group) - np.mean(measurements))**2 for group in measurements_grouped)\n",
    "        sst = sum((x - np.mean(measurements))**2 for x in measurements)\n",
    "        \n",
    "        if sst == 0:\n",
    "            return 0\n",
    "        \n",
    "        return np.sqrt(ssb / sst)\n",
    "\n",
    "    def cramers_v(self, x, y):\n",
    "        confusion_matrix = pd.crosstab(x, y)\n",
    "        chi2 = chi2_contingency(confusion_matrix)[0]\n",
    "        n = confusion_matrix.sum().sum()\n",
    "        phi2 = chi2 / n\n",
    "        r, k = confusion_matrix.shape\n",
    "        phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "        rcorr = r - ((r-1)**2)/(n-1)\n",
    "        kcorr = k - ((k-1)**2)/(n-1)\n",
    "        return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "    def correlation_analysis(self, X):\n",
    "        numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "        categorical_cols = self.identify_categorical_columns(X)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        categorical_cols = [col for col in categorical_cols if col not in numeric_cols]\n",
    "\n",
    "        print(f\"Numeric columns: {numeric_cols}\")\n",
    "        print(f\"Categorical columns: {categorical_cols}\")\n",
    "\n",
    "        # Numeric correlations\n",
    "        if len(numeric_cols) > 1:\n",
    "            corr_matrix = X[numeric_cols].corr()\n",
    "            \n",
    "            # Create the heatmap\n",
    "            fig = go.Figure(data=go.Heatmap(\n",
    "                        z=corr_matrix.values,\n",
    "                        x=corr_matrix.columns,\n",
    "                        y=corr_matrix.index,\n",
    "                        colorscale='RdBu',\n",
    "                        zmin=-1, zmax=1))\n",
    "            \n",
    "            # Add text annotations\n",
    "            for i, row in enumerate(corr_matrix.values):\n",
    "                for j, value in enumerate(row):\n",
    "                    fig.add_annotation(\n",
    "                        x=corr_matrix.columns[j],\n",
    "                        y=corr_matrix.index[i],\n",
    "                        text=f\"{value:.2f}\",\n",
    "                        showarrow=False,\n",
    "                        font=dict(color='black' if abs(value) < 0.7 else 'white')\n",
    "                    )\n",
    "            \n",
    "            fig.update_layout(\n",
    "                title='Correlation Matrix of Numeric Features',\n",
    "                width=1000, \n",
    "                height=800,\n",
    "                xaxis_showgrid=False,\n",
    "                yaxis_showgrid=False,\n",
    "                xaxis_side='top'\n",
    "            )\n",
    "            \n",
    "            plot_html = fig.to_html(full_html=False)\n",
    "            self.add_to_report(\"Numeric Correlation Matrix\", plot_html)\n",
    "            print(\"Numeric correlation matrix plotted\")\n",
    "        else:\n",
    "            print(\"Not enough numeric columns for correlation analysis\")\n",
    "            self.add_to_report(\"Numeric Correlation Matrix\", \"Not enough numeric columns for correlation analysis.\")\n",
    "\n",
    "        # Categorical correlations\n",
    "        if len(categorical_cols) > 1:\n",
    "            cat_correlations = defaultdict(dict)\n",
    "            for col1 in categorical_cols:\n",
    "                for col2 in categorical_cols:\n",
    "                    if col1 != col2:\n",
    "                        cat_correlations[col1][col2] = self.cramers_v(X[col1], X[col2])\n",
    "\n",
    "            cat_corr_matrix = pd.DataFrame(cat_correlations).fillna(1)\n",
    "            \n",
    "            fig = go.Figure(data=go.Heatmap(\n",
    "                        z=cat_corr_matrix.values,\n",
    "                        x=cat_corr_matrix.columns,\n",
    "                        y=cat_corr_matrix.index,\n",
    "                        colorscale='Viridis',\n",
    "                        zmin=0, zmax=1))\n",
    "            \n",
    "            fig.update_layout(title=\"Cramer's V Correlation Matrix of Categorical Features\",\n",
    "                            width=1000, height=800)\n",
    "            \n",
    "            plot_html = fig.to_html(full_html=False)\n",
    "            self.add_to_report(\"Categorical Correlation Matrix\", plot_html)\n",
    "            print(\"Categorical correlation matrix plotted\")\n",
    "        else:\n",
    "            print(\"Not enough categorical columns for correlation analysis\")\n",
    "            self.add_to_report(\"Categorical Correlation Matrix\", \"Not enough categorical columns for correlation analysis.\")\n",
    "\n",
    "        if len(numeric_cols) > 0 and len(categorical_cols) > 0:\n",
    "            num_cat_correlations = defaultdict(dict)\n",
    "            for num_col in numeric_cols:\n",
    "                for cat_col in categorical_cols:\n",
    "                    num_cat_correlations[num_col][cat_col] = self.compute_correlation_ratio(X[cat_col], X[num_col])\n",
    "\n",
    "            num_cat_corr_matrix = pd.DataFrame(num_cat_correlations)\n",
    "            \n",
    "            # Custom color scale from light to dark\n",
    "            colors = ['#f7fbff', '#deebf7', '#c6dbef', '#9ecae1', '#6baed6', '#4292c6', '#2171b5', '#08519c', '#08306b']\n",
    "            \n",
    "            fig = go.Figure(data=go.Heatmap(\n",
    "                        z=num_cat_corr_matrix.values,\n",
    "                        x=num_cat_corr_matrix.columns,\n",
    "                        y=num_cat_corr_matrix.index,\n",
    "                        colorscale=colors,\n",
    "                        zmin=0, zmax=1))\n",
    "            \n",
    "            # Add text annotations\n",
    "            for i, row in enumerate(num_cat_corr_matrix.values):\n",
    "                for j, value in enumerate(row):\n",
    "                    fig.add_annotation(\n",
    "                        x=num_cat_corr_matrix.columns[j],\n",
    "                        y=num_cat_corr_matrix.index[i],\n",
    "                        text=f\"{value:.2f}\",\n",
    "                        showarrow=False,\n",
    "                        font=dict(color='black' if value < 0.7 else 'white')\n",
    "                    )\n",
    "            \n",
    "            fig.update_layout(\n",
    "                title=\"Correlation Ratio between Numeric and Categorical Features\",\n",
    "                width=1000, \n",
    "                height=800,\n",
    "                xaxis_showgrid=False,\n",
    "                yaxis_showgrid=False,\n",
    "                xaxis_side='top'\n",
    "            )\n",
    "            \n",
    "            plot_html = fig.to_html(full_html=False)\n",
    "            self.add_to_report(\"Numeric-Categorical Correlation Matrix\", plot_html)\n",
    "            print(\"Numeric-Categorical correlation matrix plotted\")\n",
    "        else:\n",
    "            print(\"Not enough numeric or categorical columns for correlation analysis\")\n",
    "            self.add_to_report(\"Numeric-Categorical Correlation Matrix\", \"Not enough numeric or categorical columns for correlation analysis.\")\n",
    "\n",
    "        print(\"Correlation analysis completed\")\n",
    "\n",
    "    def save_plot_to_report(self, title):\n",
    "        img_buf = BytesIO()\n",
    "        plt.savefig(img_buf, format='png', dpi=300, bbox_inches='tight')\n",
    "        img_str = base64.b64encode(img_buf.getvalue()).decode()\n",
    "        self.add_to_report(title, f'<img src=\"data:image/png;base64,{img_str}\" alt=\"{title}\">')\n",
    "        plt.close()  \n",
    "\n",
    "    def check_missing_values(self, data):\n",
    "        missing_values = data.isnull().sum()\n",
    "        missing_percentages = 100 * missing_values / len(data)\n",
    "        missing_table = pd.concat([missing_values, missing_percentages], axis=1, keys=['Total', 'Percent'])\n",
    "        missing_table = missing_table[missing_table['Total'] > 0].sort_values('Total', ascending=False)\n",
    "        \n",
    "        if missing_table.empty:\n",
    "            self.add_to_report(\"Missing Values\", \"No missing values found in the dataset.\")\n",
    "        else:\n",
    "            self.add_to_report(\"Missing Values\", f\"Missing values found:\\n{missing_table.to_html()}\")\n",
    "\n",
    "    def check_duplicates(self, data):\n",
    "        n_duplicates = data.duplicated().sum()\n",
    "        if n_duplicates > 0:\n",
    "            self.add_to_report(\"Duplicate Values\", f\"Found {n_duplicates} duplicate rows. These will be removed.\")\n",
    "            data = data.drop_duplicates()\n",
    "        else:\n",
    "            self.add_to_report(\"Duplicate Values\", \"No duplicate rows found.\")\n",
    "        return data\n",
    "    \n",
    "    def remove_duplicate_report_entries(self):\n",
    "        seen_titles = set()\n",
    "        unique_report = []\n",
    "        for item in self.report:\n",
    "            if item['title'] not in seen_titles:\n",
    "                seen_titles.add(item['title'])\n",
    "                unique_report.append(item)\n",
    "        self.report = unique_report\n",
    "\n",
    "    def identify_categorical_columns(self, X):\n",
    "        object_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "        numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "        low_cardinality_cols = [col for col in numeric_cols if X[col].nunique() < 10 and col not in object_cols]\n",
    "        return list(object_cols) + low_cardinality_cols\n",
    "    \n",
    "    def handle_missing_values(self, X):\n",
    "        missing_values = X.isnull().sum()\n",
    "        has_missing = missing_values.sum() > 0\n",
    "\n",
    "        if not has_missing:\n",
    "            return X  # Return the original dataframe if no missing values\n",
    "\n",
    "        # Separate numerical and categorical columns\n",
    "        numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "        categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "        # Impute numerical columns with median\n",
    "        if len(numeric_features) > 0 and missing_values[numeric_features].sum() > 0:\n",
    "            num_imputer = SimpleImputer(strategy='median')\n",
    "            X[numeric_features] = num_imputer.fit_transform(X[numeric_features])\n",
    "            self.add_to_report(\"Handling Missing Values (Numeric)\", \"Numeric missing values were imputed using median strategy.\")\n",
    "\n",
    "        # Impute categorical columns with most frequent value\n",
    "        if len(categorical_features) > 0 and missing_values[categorical_features].sum() > 0:\n",
    "            cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "            X[categorical_features] = cat_imputer.fit_transform(X[categorical_features])\n",
    "            self.add_to_report(\"Handling Missing Values (Categorical)\", \"Categorical missing values were imputed using most frequent value strategy.\")\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def create_pair_plot(self, X, y):\n",
    "        # Combine features and target\n",
    "        data = pd.concat([X, y], axis=1)\n",
    "        \n",
    "        # Handle date columns\n",
    "        date_columns = data.select_dtypes(include=['object']).columns[\n",
    "            data.select_dtypes(include=['object']).apply(lambda col: col.str.match(r'\\d{2}/\\d{2}/\\d{2}').all())\n",
    "        ]\n",
    "        for col in date_columns:\n",
    "            data[col] = pd.to_datetime(data[col], format='%d/%m/%y')\n",
    "            data[f'{col}_year'] = data[col].dt.year\n",
    "            data[f'{col}_month'] = data[col].dt.month\n",
    "            data[f'{col}_day'] = data[col].dt.day\n",
    "            data = data.drop(col, axis=1)\n",
    "        \n",
    "        # Select only numeric columns\n",
    "        numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "        data = data[numeric_cols]\n",
    "        \n",
    "        # Select a subset of features if there are too many\n",
    "        if len(data.columns) > 10:\n",
    "            corr = data.corr()[y.name].abs().sort_values(ascending=False)\n",
    "            top_features = corr.index[:9]  # Select top 9 features plus target\n",
    "            data = data[top_features]\n",
    "        \n",
    "        # Create the pair plot\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.pairplot(data, hue=y.name, diag_kind='kde', plot_kws={'alpha': 0.6})\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save the plot\n",
    "        img_buf = BytesIO()\n",
    "        plt.savefig(img_buf, format='png', dpi=300)\n",
    "        img_str = base64.b64encode(img_buf.getvalue()).decode()\n",
    "        plt.close()\n",
    "        \n",
    "        self.add_to_report(\"Pair Plot\", f'<img src=\"data:image/png;base64,{img_str}\" alt=\"Pair Plot\">')\n",
    "\n",
    "    def feature_engineering(self, X):\n",
    "        categorical_cols = self.identify_categorical_columns(X)\n",
    "        numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "        numeric_transformer = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        categorical_transformer = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', numeric_transformer, numeric_cols),\n",
    "                ('cat', categorical_transformer, categorical_cols)\n",
    "            ])\n",
    "\n",
    "        return preprocessor\n",
    "    \n",
    "    def train_and_evaluate(self, X_train, y_train, X_val, y_val):\n",
    "        results = []\n",
    "        for name, model in self.models.items():\n",
    "            model.fit(X_train, y_train)\n",
    "            mse = mean_squared_error(y_val, model.predict(X_val))\n",
    "            r2 = r2_score(y_val, model.predict(X_val))\n",
    "            results.append({'model': name, 'mse': mse, 'r2': r2})\n",
    "            if mse < self.best_score:\n",
    "                self.best_score = mse\n",
    "                self.best_model = name\n",
    "\n",
    "        self.add_to_report(\"Model Training and Evaluation\", pd.DataFrame(results).to_html())\n",
    "        self.visualize_model_comparison(results)\n",
    "\n",
    "    def hyperparameter_tuning(self, X_train, y_train):\n",
    "        param_distributions = {\n",
    "            'DecisionTree': {\n",
    "                'max_depth': randint(1, 20),\n",
    "                'min_samples_split': randint(2, 20),\n",
    "                'min_samples_leaf': randint(1, 20)\n",
    "            },\n",
    "            'KNN': {\n",
    "                'n_neighbors': randint(1, 20),\n",
    "                'weights': ['uniform', 'distance'],\n",
    "                'p': [1, 2]\n",
    "            }\n",
    "        }\n",
    "\n",
    "        if self.best_model in param_distributions:\n",
    "            random_search = RandomizedSearchCV(\n",
    "                self.models[self.best_model],\n",
    "                param_distributions=param_distributions[self.best_model],\n",
    "                n_iter=50,\n",
    "                cv=5,\n",
    "                n_jobs=-1,\n",
    "                random_state=42,\n",
    "                scoring='neg_mean_squared_error'\n",
    "            )\n",
    "\n",
    "            random_search.fit(X_train, y_train)\n",
    "            self.best_params = random_search.best_params_\n",
    "            self.best_score = -random_search.best_score_\n",
    "\n",
    "            self.add_to_report(\"Hyperparameter Tuning\", \n",
    "                               f\"Best Model: {self.best_model}\\n\"\n",
    "                               f\"Best Parameters: {self.best_params}\\n\"\n",
    "                               f\"Best MSE: {self.best_score}\")\n",
    "        else:\n",
    "            self.add_to_report(\"Hyperparameter Tuning\", \n",
    "                               f\"No hyperparameter tuning performed for {self.best_model}\")\n",
    "\n",
    "    def visualize_model_comparison(self, results):\n",
    "        df_results = pd.DataFrame(results)\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x='model', y='mse', data=df_results)\n",
    "        plt.title('Model Comparison - Mean Squared Error')\n",
    "        plt.xlabel('Models')\n",
    "        plt.ylabel('Mean Squared Error')\n",
    "        plt.xticks(rotation=45)\n",
    "        \n",
    "        img_buf = BytesIO()\n",
    "        plt.savefig(img_buf, format='png')\n",
    "        img_str = base64.b64encode(img_buf.getvalue()).decode()\n",
    "        \n",
    "        self.add_to_report(\"Model Comparison Visualization\", f'<img src=\"data:image/png;base64,{img_str}\" alt=\"Model Comparison\">')\n",
    "\n",
    "    def handle_date_columns(self, X):\n",
    "        date_columns = X.select_dtypes(include=['object']).columns[X.select_dtypes(include=['object']).apply(lambda col: col.str.match(r'\\d{2}/\\d{2}/\\d{2}').all())]\n",
    "        \n",
    "        for col in date_columns:\n",
    "            X[col] = pd.to_datetime(X[col], format='%d/%m/%y')\n",
    "            X[f'{col}_year'] = X[col].dt.year\n",
    "            X[f'{col}_month'] = X[col].dt.month\n",
    "            X[f'{col}_day'] = X[col].dt.day\n",
    "            X[f'{col}_dayofweek'] = X[col].dt.dayofweek\n",
    "            X = X.drop(col, axis=1)\n",
    "        \n",
    "        # Only add to report if it hasn't been added before\n",
    "        if not hasattr(self, 'date_columns_processed'):\n",
    "            self.add_to_report(\"Date Column Handling\", f\"Processed date columns: {', '.join(date_columns)}\")\n",
    "            self.date_columns_processed = True\n",
    "        \n",
    "        return X\n",
    "\n",
    "    def visualize_feature_importance(self, X, y):\n",
    "        model = DecisionTreeRegressor(random_state=42)\n",
    "            \n",
    "        # Fit the model on the preprocessed data\n",
    "        X_processed = self.feature_engineer.fit_transform(X)\n",
    "        model.fit(X_processed, y)\n",
    "            \n",
    "        # Get feature names after preprocessing\n",
    "        feature_names = (self.feature_engineer.named_transformers_['num'].get_feature_names_out().tolist() + \n",
    "                            self.feature_engineer.named_transformers_['cat'].get_feature_names_out().tolist())\n",
    "            \n",
    "        importances = model.feature_importances_\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "            \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.title(\"Feature Importances\")\n",
    "        plt.bar(range(len(importances)), importances[indices])\n",
    "        plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=90)\n",
    "        plt.tight_layout()\n",
    "            \n",
    "        img_buf = BytesIO()\n",
    "        plt.savefig(img_buf, format='png')\n",
    "        img_str = base64.b64encode(img_buf.getvalue()).decode()\n",
    "            \n",
    "        self.add_to_report(\"Feature Importance Visualization\", f'<img src=\"data:image/png;base64,{img_str}\" alt=\"Feature Importance\">')\n",
    "\n",
    "    def fit(self, train_file, test_file):\n",
    "        train_data = pd.read_csv(train_file)\n",
    "        test_data = pd.read_csv(test_file)\n",
    "\n",
    "        # Capture train and test data heads\n",
    "        self.capture_dataframe_head(train_data, \"Training Data Preview\")\n",
    "        self.capture_dataframe_head(test_data, \"Test Data Preview\")\n",
    "\n",
    "        print(f\"Train data shape: {train_data.shape}\")\n",
    "        print(f\"Test data shape: {test_data.shape}\")\n",
    "\n",
    "        self.add_to_report(\"Data Overview\", f\"Training data shape: {train_data.shape}\\nTest data shape: {test_data.shape}\")\n",
    "\n",
    "        print(f\"Train data columns: {train_data.columns.tolist()}\")\n",
    "        print(f\"Target column: {self.target_column}\")\n",
    "\n",
    "        if self.target_column is None:\n",
    "            self.target_column = train_data.columns[-1]\n",
    "            print(f\"Automatically selected target column: {self.target_column}\")\n",
    "        else:\n",
    "            if self.target_column not in train_data.columns:\n",
    "                raise ValueError(f\"Specified target column '{self.target_column}' not found in the training data.\")\n",
    "            print(f\"User-specified target column: {self.target_column}\")\n",
    "\n",
    "        X_train = train_data.drop(self.target_column, axis=1)\n",
    "        y_train = train_data[self.target_column]\n",
    "        X_test = test_data.drop(self.target_column, axis=1) if self.target_column in test_data.columns else test_data\n",
    "\n",
    "        print(f\"X_train shape: {X_train.shape}\")\n",
    "        print(f\"y_train shape: {y_train.shape}\")\n",
    "        print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "        # Check for missing values and duplicates\n",
    "        self.check_missing_values(X_train)\n",
    "        X_train = self.check_duplicates(X_train)\n",
    "        \n",
    "        # Handle missing values\n",
    "        X_train = self.handle_missing_values(X_train)\n",
    "\n",
    "        # Handle date columns\n",
    "        X_train = self.handle_date_columns(X_train)\n",
    "        X_test = self.handle_date_columns(X_test)\n",
    "\n",
    "        # Create pair plot after handling date columns\n",
    "        self.create_pair_plot(X_train, y_train)\n",
    "\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "        print(f\"After split - X_train shape: {X_train.shape}\")\n",
    "        print(f\"After split - y_train shape: {y_train.shape}\")\n",
    "        print(f\"After split - X_val shape: {X_val.shape}\")\n",
    "        print(f\"After split - y_val shape: {y_val.shape}\")\n",
    "\n",
    "        self.correlation_analysis(X_train)\n",
    "\n",
    "        # Feature engineering\n",
    "        self.feature_engineer = self.feature_engineering(X_train)\n",
    "        X_train_featured = self.feature_engineer.fit_transform(X_train)\n",
    "        X_val_featured = self.feature_engineer.transform(X_val)\n",
    "\n",
    "        # Remove feature selection and PCA steps for simplicity\n",
    "        self.train_and_evaluate(X_train_featured, y_train, X_val_featured, y_val)\n",
    "        self.hyperparameter_tuning(X_train_featured, y_train)\n",
    "\n",
    "        final_model = self.models[self.best_model]\n",
    "        if self.best_params:\n",
    "            final_model.set_params(**self.best_params)\n",
    "        final_model.fit(X_train_featured, y_train)\n",
    "\n",
    "        X_test_featured = self.feature_engineer.transform(X_test)\n",
    "\n",
    "        y_pred = final_model.predict(X_test_featured)\n",
    "\n",
    "        self.visualize_feature_importance(X_train, y_train)\n",
    "\n",
    "        mse = mean_squared_error(y_val, final_model.predict(X_val_featured))\n",
    "        r2 = r2_score(y_val, final_model.predict(X_val_featured))\n",
    "        self.add_to_report(\"Final Model Performance\", f\"Mean Squared Error: {mse}\\nR-squared: {r2}\")\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def generate_html_report(self):\n",
    "        # Create directories for assets if they don't exist\n",
    "        for dir_name in ['report_assets/css', 'report_assets/js', 'report_assets/images']:\n",
    "            os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "        # Extract Plotly JS code and save to a file\n",
    "        plotly_js = next((item['content'] for item in self.report if item['content'].startswith('/*! For license information')), \"\")\n",
    "        if plotly_js:\n",
    "            with open('report_assets/js/plotly.min.js', 'w') as f:\n",
    "                f.write(plotly_js)\n",
    "\n",
    "        # Extract CSS and save to a file\n",
    "        css_content = \"\"\"\n",
    "        body {\n",
    "            font-family: Arial, sans-serif;\n",
    "            line-height: 1.6;\n",
    "            color: #333;\n",
    "            max-width: 1200px;\n",
    "            margin: 0 auto;\n",
    "            padding: 20px;\n",
    "        }\n",
    "        h1 {\n",
    "            color: #2c3e50;\n",
    "            border-bottom: 2px solid #2c3e50;\n",
    "            padding-bottom: 10px;\n",
    "        }\n",
    "        h2 {\n",
    "            color: #34495e;\n",
    "            margin-top: 30px;\n",
    "        }\n",
    "        pre {\n",
    "            background-color: #f4f4f4;\n",
    "            border: 1px solid #ddd;\n",
    "            border-left: 3px solid #f36d33;\n",
    "            color: #666;\n",
    "            page-break-inside: avoid;\n",
    "            font-family: monospace;\n",
    "            font-size: 15px;\n",
    "            line-height: 1.6;\n",
    "            margin-bottom: 1.6em;\n",
    "            max-width: 100%;\n",
    "            overflow: auto;\n",
    "            padding: 1em 1.5em;\n",
    "            display: block;\n",
    "            word-wrap: break-word;\n",
    "        }\n",
    "        img {\n",
    "            max-width: 100%;\n",
    "            height: auto;\n",
    "            display: block;\n",
    "            margin: 20px auto;\n",
    "        }\n",
    "        table {\n",
    "            border-collapse: collapse;\n",
    "            width: 100%;\n",
    "            margin-bottom: 1em;\n",
    "        }\n",
    "        th, td {\n",
    "            text-align: left;\n",
    "            padding: 8px;\n",
    "            border-bottom: 1px solid #ddd;\n",
    "        }\n",
    "        tr:nth-child(even) {\n",
    "            background-color: #f2f2f2;\n",
    "        }\n",
    "        .dataframe {\n",
    "            border-collapse: collapse;\n",
    "            margin: 25px 0;\n",
    "            font-size: 0.9em;\n",
    "            font-family: sans-serif;\n",
    "            min-width: 400px;\n",
    "            box-shadow: 0 0 20px rgba(0, 0, 0, 0.15);\n",
    "        }\n",
    "        .dataframe thead tr {\n",
    "            background-color: #009879;\n",
    "            color: #ffffff;\n",
    "            text-align: left;\n",
    "        }\n",
    "        .dataframe th,\n",
    "        .dataframe td {\n",
    "            padding: 12px 15px;\n",
    "        }\n",
    "        .dataframe tbody tr {\n",
    "            border-bottom: 1px solid #dddddd;\n",
    "        }\n",
    "        .dataframe tbody tr:nth-of-type(even) {\n",
    "            background-color: #f3f3f3;\n",
    "        }\n",
    "        .dataframe tbody tr:last-of-type {\n",
    "            border-bottom: 2px solid #009879;\n",
    "        }\n",
    "        div {\n",
    "            overflow-x: auto;\n",
    "        }\n",
    "        \"\"\"\n",
    "        with open('report_assets/css/styles.css', 'w') as f:\n",
    "            f.write(css_content)\n",
    "\n",
    "        # Generate HTML content\n",
    "        html_content = \"\"\"\n",
    "        <!DOCTYPE html>\n",
    "        <html lang=\"en\">\n",
    "        <head>\n",
    "            <meta charset=\"UTF-8\">\n",
    "            <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "            <title>ExtraML Report</title>\n",
    "            <link rel=\"stylesheet\" href=\"report_assets/css/styles.css\">\n",
    "            <script src=\"report_assets/js/plotly.min.js\"></script>\n",
    "        </head>\n",
    "        <body>\n",
    "            <h1>ExtraML Report</h1>\n",
    "        \"\"\"\n",
    "\n",
    "        for i, item in enumerate(self.report):\n",
    "            html_content += f\"<h2>{item['title']}</h2>\"\n",
    "            if item['content'].startswith('<img'):\n",
    "                # Extract base64 data and save as image file\n",
    "                img_data = item['content'].split(',')[1]\n",
    "                img_binary = base64.b64decode(img_data)\n",
    "                img_filename = f'report_assets/images/image_{i}.png'\n",
    "                with open(img_filename, 'wb') as f:\n",
    "                    f.write(img_binary)\n",
    "                \n",
    "                # Use lazy loading for images\n",
    "                html_content += f'<img src=\"{img_filename}\" alt=\"{item[\"title\"]}\" loading=\"lazy\">'\n",
    "            elif item['content'].startswith('<table'):\n",
    "                html_content += item['content']\n",
    "            elif not item['content'].startswith('/*! For license information'):\n",
    "                html_content += f\"<pre>{item['content']}</pre>\"\n",
    "\n",
    "        html_content += \"\"\"\n",
    "        </body>\n",
    "        </html>\n",
    "        \"\"\"\n",
    "\n",
    "        with open('extraml_report.html', 'w', encoding='utf-8') as f:\n",
    "            f.write(html_content)\n",
    "\n",
    "        print(\"HTML report generated: extraml_report.html\")\n",
    "\n",
    "    def run_analysis(self, train_file, test_file):\n",
    "        self.fit(train_file, test_file)\n",
    "        self.remove_duplicate_report_entries()  \n",
    "        self.generate_html_report()\n",
    "        print(\"Analysis complete. Check the HTML report for details.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (12165, 11)\n",
      "Test data shape: (5214, 10)\n",
      "Train data columns: ['Date', 'Weather', 'Year', 'Month', 'Hour', 'Holiday', 'Normalized_Temperature', 'Normalized_Feeling_Temperature', 'Normalized_Humidity', 'Windspeed', 'Count_of_Rented_Bikes']\n",
      "Target column: Count_of_Rented_Bikes\n",
      "User-specified target column: Count_of_Rented_Bikes\n",
      "X_train shape: (12165, 10)\n",
      "y_train shape: (12165,)\n",
      "X_test shape: (5214, 10)\n",
      "After split - X_train shape: (9732, 13)\n",
      "After split - y_train shape: (9732,)\n",
      "After split - X_val shape: (2433, 13)\n",
      "After split - y_val shape: (2433,)\n",
      "Numeric columns: Index(['Year', 'Month', 'Hour', 'Holiday', 'Normalized_Temperature',\n",
      "       'Normalized_Feeling_Temperature', 'Normalized_Humidity', 'Windspeed'],\n",
      "      dtype='object')\n",
      "Categorical columns: ['Weather']\n",
      "Numeric correlation matrix plotted\n",
      "Not enough categorical columns for correlation analysis\n",
      "Numeric-Categorical correlation matrix plotted\n",
      "Correlation analysis completed\n"
     ]
    }
   ],
   "source": [
    "extra_ml_clf = ExtraML(problem_type='regression',target_column=\"Count_of_Rented_Bikes\")\n",
    "extra_ml_clf.run_analysis('train.csv','test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
